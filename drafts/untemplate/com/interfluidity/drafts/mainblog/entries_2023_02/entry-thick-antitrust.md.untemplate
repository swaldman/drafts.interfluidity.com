> val UntemplateAttributes = immutable.Map[String,Any] (
>   "Title"     -> "Thick antitrust",
>   "Author"    -> "Steve Randy Waldman",
>   "PubDate"   -> "2023-02-24T12:25:00-05:00",
>   // "Anchor"    -> "first-post"
> )

given PageBase = PageBase.fromPage(input.renderLocation)

(input : MainBlog.EntryInput)[]~()>      ### modify Title/Author/Pubdate above, add markdown or html below!

In the graphic at the heart of [the previous draft](##section-230-quadrants), I used the term "thick antitrust".
I want to unpack that a bit.

Often when we think of antitrust, we think of "a cop on the beat", blocking mergers, policing price collusion,
breaking up consolidations of economic power. And we do want such cops on the beat! I am very grateful that we
have [Lina Khan](https://en.wikipedia.org/wiki/Lina_Khan) as the chair of the FTC.

However, a very [old](https://www.interfluidity.com/posts/1258156478.shtml) [theme](https://www.interfluidity.com/v2/197.html)
at _interfluidity_ is that we should prefer structural over supervisory solutions.
Regulators come and go, enforcement of a given regulatory scheme may be a priority of one administration and then
actively undermined by the next. Industry interests are consistent and persistent in a way that political fashions
are not. Over time, the probability that supervisory agencies will become largely captured by the industries they
regulate approaches one, until, predicatably, a crisis emerges from the misregulation which provokes the politicians
pick up their pitchforks for a minute and the cycle begins anew.

If you've given any thought to the idea of structural racism, you understand that subtle structural facts can lead to outcomes that are quite
durable and are perceived by the broad public as ordinary or even "natural". But if we can encode vice into structure, we can
also encode virtue.

The best regulation does not look like regulation at all, but is embedded in the structure of institutions
we take for granted, yielding desirable outcomes without very much need for continual enforcement. For
example, Jane Jacobs taught us that the broad, tranquil plazas mid-20th-century urban planners
imagined and tried to design were structurally incoherent. You don't get tranquility in vast, mostly empty
urban spaces, you get crime. Yes, you can try to address this by hiring lots of cops to supervise the space.
But a better approach is to encourage busy, bustling streetscapes. "Eyes on the street", along with the proprietary interest
of shopkeepers and neighbors in the safety of their neighborhood, will do a far better job, more reliably, 
more cheaply, largely invisibly.

"Thick antitrust" is the idea that we should craft a regulatory environment in which undesirable forms of scale
are simply not adaptive. We can rely less on fragile policing of economic power when provision at scale is
uneconomic.

Usually, regulation seeks to _enable_ scale on efficiency grounds,
and it is not always wrong to do so. How often do you hear lobbyists and regulators alike aver that firms "should not have
to contend with 50 different regulatory schemes in 50 different states"? Whether by harmonizing state laws or imposing
a Federal framework that preempts them, we usually work to make the marketplace friendly to large-scale business.

And often that's the right thing to do! When we want a national marketplace in a good or service, when we think there
are [socially valuable economies of scale](https://www.interfluidity.com/v2/8882.html) such that competition should be
structured between firms that serve or aspire to serve the national market, then we should harmonize or preempt. We can gain
scale efficiencies and prevent predation by local monopolies if we sustain a competitive national market.

But that "if" is critical. A single national marketplace is very legible to businesspeople interested in
consolidating to gain market power, and to financiers who understand that scarcity and control is the only path
of sustainable "alpha". When we encourage scale,
we may gain efficiencies, but we accept tacit liabilities, including the cost of vigilant supervision
and the much greater cost of forseeable failures of that supervision. It's a balance.

For many activities, it's better simply to render firm-level scale uneconomical. Of course we want the "network effects"
on the internet. Network effects are why we built the internet in the first place, duh. But we want the value that comes from interconnection
to accrue to participants of the network broadly, rather than being captured within a few very fortunate firms. Precisely because network
effects are so strong on the internet, we should seek regulation that favors enterprise at smaller scales. The value of the network
can then be captured only by interoperability, by adherence to open standards under which many participants compete on fairly equal terms
to provide and profit from connectivity.

Because intrafirm coordination costs are far lower than the burdens associated with developing
open standards, it will always be possible for an "innovator" to provide more value faster by growing network applications under its sole
control. But this is the first step towards Cory Doctorow's ["enshittification" dynamic](https://pluralistic.net/2023/01/21/potemkin-ai/).
Yes, "blitzscaling" creates an initial spurt of value for customers that is real, and could not have been created so quickly
without the proprietary startup. But the cost of that front-loaded fast growth is a tail of predation and 
extraction and stagnation extending far into the future. The "innovator" will have enclosed for itself all the value that we, the network,
create, and will make it difficult for new innovators to emerge.

It isn't worth it. On the internet, and in finance (another domain where network effects entrench
pernicious concentrations of power in early winners), we want to craft
regulatory regimes under which scale becomes burdensome. But effective
regulation demands elegance. If you just prohibit scale, a million clever lawyers will synthesize a megafirm out of
a thousand LLCs, and a perpetual cat-and-mouse game will begin.

That's much, much better than doing nothing, just bend over and get
Googled! But it's still not great.

One elegant way to discourage market power in an industry is to privilege, for regulatory purposes, aspects of the business that (in the ultimate
tech-firm insult) "do not scale". Perhaps, as Section 230 proponents argue, you don't want to just default to
the tort system as a regulator of internet firms, safe harbors are necessary to ensure an ecosystem of open and vibrant internet
forums. Okay.

But then rather than offering a blanket shield to any entity that can quilt their speech out of third-party content,
why not craft a safe harbor for firms that demonstrate that they
moderate and curate with careful attention to context by people informationally local to the speakers and familiar with
subcultural norms? [^1]

Alternatively, some industries can be constructed from whole cloth out of regulation.
Notaries, for example, exist to fill a slot created by regulatory norms. So does the legal industry more broadly. And modern
banking. Most banks hold not a nugget of gold in any vault, all of the goods and services they provide are made of regulatory fabrications,
yet we perceive banks as perfectly natural and quite essential.

There's been wide-ranging debate on the concept of "information fiduciaries", introduced most prominently by [Jack Balkin and
Jonathan Zittrain](https://www.theatlantic.com/technology/archive/2016/10/information-fiduciary/502346/). Balkin and Zittrain
argue that we can make our peace with the megaplatforms that have become both indispensible and intolerable by 
imposing upon them a framework of legal obligations under which they'd be required they put users' interests
before their own in their handling of the data we entrust to
them.

Critics, [including](https://harvardlawreview.org/2019/12/a-skeptical-view-of-information-fiduciaries/)
the redoubtable Lina Khan, are correctly skeptical. Firms like Facebook, Google, Twitter exist at the scale they
do only because of business models based on surveillance of users and an undesirable influence over
our collective cognition. Imposing a "fiduciary" obligation upon them would either wrap these harms
beneath a sanctimonious legal fig leaf, or else necessitate a transformation tantamount to complete destruction
of these firms in their present form.

But what if we defined an entirely new category of actor, an intermediary who would have legal roles like a notary (current pratices
surrounding electronic signatures are absurd), who would function as caretakers of personal data, intermediating between ordinary
humans and monsters like Google, with whom nonprofessional individuals cannot meaningfully contend? And what if we enshrined, as a
foundational requirement of this new industry, a limit on the ratio between legally responsible humans and the clients to whom they
owe their duty?

It wouldn't scale. Thank goodness.

[^1]: Of course, forums should still address any external harms their services cause. If defamatory speech is public in
a way that would do continuing injury, that might override a general deference to within-communities norms. But careful moderators might be extended
more grace in these circumstances than shoddy moderators.






